<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Gensim: Topic Modelling for Humans - an overview by Yanir Seroussi</title>

		<meta name="description" content="An overview of the Python Gensim package, including a brief explanation of topic modelling and a live demo.">
		<meta name="author" content="Yanir Seroussi">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/black.css" id="theme">

		<!-- Code syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->

        <style type="text/css">
            .reveal p {
                text-align: left;
                margin: 10px 0;
            }

            .center {
                text-align: center;
            }

            .right {
                text-align: right !important;
            }

            .indent {
                padding-left: 300px !important;
            }

            .pad-top {
                padding-top: 30px !important;
            }

            .no-margin {
                margin: 0 !important;
            }

            .reveal .medium {
                font-size: .8em;
                line-height: 1.25em;
            }

            .reveal .small {
                font-size: .6em;
                line-height: 1.2em;
            }

            .reveal img {
                border: 0;
            }

            .reveal ul, .reveal ol {
                display: block;
            }

            .reveal ul {
                margin: 0 0 0 2em;
            }

            .reveal h1, .reveal h2, .reveal h3, .reveal h4, .reveal h5, .reveal h6 {
                text-transform: none;
            }

            .img-source-caption {
                text-align: right;
                font-size: 14px !important;
                line-height: 10px !important;
                padding-bottom: 10px !important;
            }
        </style>
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>gensim</h1>
					<h3>Topic Modelling for Humans</h3>
					<h4>An overview by Yanir Seroussi</h4>
          <h6><small>
              <a href="http://yanirseroussi.com" target="_blank">yanirseroussi.com</a> |
              <a href="https://twitter.com/yanirseroussi" target="_blank">@yanirseroussi</a> |
              <a href="https://linkedin.com/in/yanirseroussi" target="_blank">linkedin.com/in/yanirseroussi</a>
          </small></h6>
				</section>

                <section>
                    <h2>Quick bio</h2>

                    <p>Originally a software engineer:</p>
                    <ul>
                         <li>BSc CompSci Technion</li>
                         <li>Intel, Qualcomm, Google</li>
                    </ul>

                    <p>Converted to a data scientist:</p>
                    <ul>
                        <li>Monash PhD: text mining and user modelling</li>
                        <li>Giveable &rarr; Hynt: recommender systems, data scientist, tech lead with many hats</li>
                    </ul>

                    <p>Over the last year:</p>
                    <ul>
                        <li>Data science consulting/contracting</li>
                        <li>Work on own projects</li>
                    </ul>
                </section>

                <section>
                    <h2>My Python history highlights</h2>

                    <dl>
                        <dt>2010</dt>
                        <dd>Converted Perl scripts to Python to impress Google</dd>

                        <dt>Early 2012</dt>
                        <dd>First Kaggle competition using Python and scikit-learn</dd>

                        <dt>Late 2012</dt>
                        <dd>Full-time Python: Django et al., first gensim experience</dd>

                        <dt>2013</dt>
                        <dd>Got my head around Fabric, pandas</dd>

                        <dt>2014</dt>
                        <dd>Life changed by IPython notebook</dd>

                        <dt>2015</dt>
                        <dd>First taste of Theano, first SyPy talk</dd>
                    </dl>
                </section>

                <section>
                    <section>
                        <h6>enough about me, let's talk about...</h6>
                        <h1>gensim</h1>
                    </section>

                    <section>
                        <h2>Topic modelling...</h2>

                        <img src="img/lda.png">
                        <div class="img-source-caption">
                            Source: <a href="http://en.wikipedia.org/wiki/Latent_Dirichlet_allocation" target="_blank">Wikipedia</a>
                        </div>

                        <ul class="medium">
                            <li>for each topic t, draw word distribution φ(t) ~ Dirichlet(β)</li>
                            <li>for each document d:
                                <ul>
                                    <li>draw a topic distribution θ(d) ~ Dirichlet(α)</li>
                                    <li>for each word index i in document d:</li>
                                    <ul>
                                        <li>draw a topic z(d, i) ~ Categorical(θ(d))</li>
                                        <li>draw the word w(d, i) ~ Categorical(φ(z(d, i)))</li>
                                    </ul>
                                </ul>
                            </li>
                        </ul>
                    </section>

                    <section>
                        <h2>...for humans *</h2>

                        <img src="img/gensim-code.png">

                        <p class="small">
                            * who speak Python
                        </p>
                    </section>
                </section>

                <section>
                    <section>
                        <h2>What is topic modelling?</h2>

                        <blockquote>
                            A topic model is a type of statistical model for discovering the abstract "topics" that occur in
                            a collection of documents.
                        </blockquote>

                        <p class="right small">- <a href="https://en.wikipedia.org/wiki/Topic_model" target="_blank">Wikipedia</a></p>

                        <ul>
                            <li>Every topic is a distribution (weighted list) over words</li>
                            <li>Every document has a distribution over topics</li>
                        </ul>

                        <p>GIGO:</p>
                        <ul>
                            <li>Topics don't necessarily make sense</li>
                            <li>Words don't have to be words</li>
                        </ul>
                    </section>

                    <section>
                        <h2>Topic modelling by example</h2>

                        <img src="img/lda-example.jpg">
                        <div class="img-source-caption">
                            Source: <a href="http://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext" target="_blank">Probabilistic Topic Models by David M. Blei</a>
                        </div>

                    </section>
                </section>

                <section>
                    <h2>What are topic models good for?</h2>

                    <ul>
                        <li>Exploring large text corpora</li>
                        <li>Information retrieval: find documents matching a query</li>
                        <li>Similarity and clustering</li>
                        <li>Recommender systems</li>
                        <li>And much more...</li>
                    </ul>
                </section>

                <section>
                    <section>
                        <h1>Gensim topic models & other cool things</h1>
                    </section>

                    <section>
                        <h2>1970s: TfidfModel</h2>

                        <p>Not really a topic model, but still useful</p>

                        <p>TF-IDF is the product of:</p>
                        <ul>
                            <li>TF: term frequency in a document</li>
                            <li>IDF: inverse document frequency of term in corpus</li>
                        </ul>

                        <p>Intuition: give high weight to words that are topic-specific</p>
                    </section>

                    <section>
                        <h2>1980-90s: LsiModel</h2>

                        <p>LSI/A: latent semantic indexing/analysis</p>

                        <p>Singular value decomposition of the frequency/tf-idf matrix, followed by dimensionality reduction</p>

                        <p>Intuition: denoise to extract latent factors/topics</p>

                        <img src="img/lsi.jpg">
                        <div class="img-source-caption">
                            Source: <a href="https://liqiangguo.wordpress.com/2011/06/09/latent-semantic-analysis/" target="_blank">Liqiang Guo</a>
                        </div>
                    </section>

                    <section>
                        <h2>2000s: LdaModel, HdpModel</h2>

                        <dl class="no-margin">
                            <dt>LDA: latent Dirichlet allocation </dt>
                            <dd>Probabilistic extension of LSI, as seen before</dd>

                            <dt>HDP: hierarchical Dirichlet process</dt>
                            <dd>Nonparametric version of LDA &ndash; no more setting a fixed number of topics</dd>
                        </dl>

                        <p>Intuition: becomes clear when you get into Bayesian stats</p>
                    </section>

                    <section>
                        <h2>2010s: Word2Vec, Doc2Vec</h2>

                        <p>Word2Vec: representing words as vectors</p>

                        <p>Not a classic topic model, inspired by deep learning</p>

                        <p>Claim to fame:</p>
                        <ul>
                            <li>woman - man + king = queen</li>
                            <li>Paris - France + Italy = Rome</li>
                            <li>breakfast cereal dinner lunch &ndash; cereal doesn't fit</li>
                        </ul>
                    </section>

                    <section>
                        <h2>Other cool things</h2>

                        <ul>
                            <li>Fast: <a href="http://radimrehurek.com/2013/09/word2vec-in-python-part-two-optimizing/" target="_blank">word2vec implementation faster than optimised C</a></li>
                            <li>Scalable:
                                <ul>
                                    <li>Distributed algorithms</li>
                                    <li>May run in constant memory on a single machine</li>
                                </ul>
                            </li>
                            <li>Production-ready: comes with its own similarity server</li>
                            <li>Handy corpus and similarity handling utils</li>
                        </ul>
                    </section>
                </section>

                <section>
                    <h1><a href="http://nbviewer.ipython.org/github/bmabey/pyLDAvis/blob/master/notebooks/Gensim%20Newsgroup.ipynb" target="_blank">Demo</a></h1>
                </section>
		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>

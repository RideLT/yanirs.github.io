doctype html
html(lang="en")
  head
    title Problem Definition

    meta(name="description",
         content="On the importance of problem definition in machine learning.")
    meta(name="author", content="Yanir Seroussi")
    meta(charset="utf-8")
    meta(name="viewport", content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no")
    meta(name="apple-mobile-web-app-capable", content="yes")
    meta(name="apple-mobile-web-app-status-bar-style", content="black-translucent")

    link(rel="stylesheet", href="css/reveal.css")
    link(rel="stylesheet", href="css/theme/night.css")
    link(rel="stylesheet", href="lib/css/zenburn.css")
    link(rel="stylesheet", href="custom.css")

    // Print and PDF exports
    script.
      var link = document.createElement('link');
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
      document.getElementsByTagName('head')[0].appendChild(link);

    <!--[if lt IE 9]><script src="lib/js/html5shiv.js"></script><![endif]-->

  body
    .reveal: .slides
      section
        h1 Problem Definition

        aside.notes: ul
          li One of the key challenges
          li What sort of problems can we handle?

      section
        section
          h2 Common data science problems

          p.fragment "We have all this data, what can we do with it?"
          p.fragment "I want my big data cluster to perform better"
          .fragment
            p "Give me actionable analytics about our customers"

            a(href="http://dilbert.com/strip/2013-01-09")
              img.pad-white(src="img/dilbert-actionable-analytics.gif")

          aside.notes: ol
            li Business problem, not solved by data scientists
            li Data engineering, vague
            li More specific, but hype-driven, requires domain expertise

        section
          h2 Better-defined problems

          ul
            li.fragment Build a model to predict sales of a marketing campaign
            li.fragment Create a system that runs campaigns that automatically adapt to customer feedback
            li.fragment Identify key objects in images
            li.fragment Improve clickthrough rates on search engine results
            li.fragment Detect whale calls from underwater recordings to prevent collisions

          aside.notes
            p Common theme: clear measurable goal, can be addressed by ML

      section
        section
          h1 Steps to solving data science problems

        section
          h2 Steps to solving data science problems

          h1 #1: Figure out what the problem is

          aside.notes: ul
            li Get as specific as possible
            li Requires domain knowledge and stakeholder consultation

        section
          h2 Steps to solving data science problems

          h1 #2: Find out how the solution will be measured

          aside.notes: ul
            li Important, challenging, critical, political
            li Separate talk

        section
          h2 Steps to solving data science problems

          h1 #3: "Solve" problem

          aside.notes
            p Two previous steps are required

        section
          h2 Solve problem?

          a(href="http://pn.ispirt.in/practical-mantras-for-lean-startup/")
            img(src="img/build-measure-learn.jpg")

          aside.notes: ul
            li Never solved, always be iterating
            li Ingrid: we only address problems, job security
            li Build-measure-learn: data-driven way of building products, also applies to ML

        section
          h2 Solve problem with ML?

          a(href="http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html")
            img(src="img/scikit-learn-map.png")

          aside.notes: ul
            li ML isn't always needed: better data? heuristic?
            li When needed, the map can help decide on algorithm

      section
        h2 Exploring the ML map

        ul
          li Base assumption: you have data and a rough idea what you want to find
          li All methods require <b>features</b> as input
          li Four main areas:
            ul
              li Supervised classification
              li Supervised regression
              li Unsupervised clustering
              li Dimensionality reduction

        aside.notes: ul
          li Features: numeric representation, more details later
          li Four areas: rest of this talk

      section
        section
          h3 Supervised classification: Definition

          p <b>Supervised:</b> we have labelled data to train on
          p <b>Classification:</b> need to predict/infer the class/category of each instance

          aside.notes: ul
            li Supervisor/teacher knows the correct answer
            li Predict means infer, not necessarily forecast

        section
          h3 Supervised classification: Example #1

          p Classifying iris species using k-nearest-neighbours

          a(href="http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html")
            img.method-example(src="img/supervised-classification-iris-knn.png")

          aside.notes: ul
            li Iris: Fisher 1936, three species, four features (length/width of sepals/petals)
            li KNN: distance in feature space, majority of K closest (tunable/1/3)
            li Example: x = 5, y = 3 &rarr; red species

        section
          h3 Supervised classification: Example #2

          p Classifying spam emails with support vector machines

          a(href="http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html")
            img.method-example.pad-white(src="img/supervised-classification-svm.png")

          aside.notes: ul
            li Features: word frequency, potentially thousands
            li Classes: spam / not spam (e.g., from users)
            li SVM: find the hyperplane that best separates data
            li Image: only two dimensions, line is the two dimensional hyperplane, hard to visualise thousands

      section
        section
          h3 Supervised regression: Definition

          p <b>Supervised:</b> we have labelled data to train on
          p <b>Regression:</b> need to predict/infer a numeric quantity for each instance

        section
          h3 Supervised regression: Example #1

          p Linear regression to predict diabetes progression

          a(href="http://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html")
            img.method-example(src="img/supervised-regression-diabetes-linear.png")

          aside.notes: ul
            li Very basic, very useful
            li Linear: It's just a line
            li Multiple dimensions/features: Hyperplane, hard to visualise

        section
          h3 Supervised regression: Example #2

          p Predicting rent with decision trees

          a(href="https://bigml.com/user/ashikiar/gallery/model/52dda1b90c0b5e2904000187/tree")
            img.method-example(src="img/supervised-regression-rent-decision-tree.png")

          aside.notes: ul
            li Many tree-based techniques
            li General idea: split by feature at each node
            li Go through prediction path

      section
        section
          h3 Unsupervised clustering: Definition

          p <b>Unsupervised:</b> no labelled training data
          p <b>Clustering:</b> group together similar instances, can be soft or hard

        section
          h3 Unsupervised clustering: Example #1

          p Discovering topics in texts with latent Dirichlet allocation

          a(href="http://cacm.acm.org/magazines/2012/4/147361-probabilistic-topic-models/fulltext")
            img.method-example(src="img/unsupervised-clustering-lda.jpg")

          aside.notes: ul
            li Features: words in documents
            li Generative story: Document has distribution over topics; topic &rarr; word
            li Distribution = frequency list
            li Mathematical tricks give us soft clusters
            li Example: Science articles, yellow genetics, green neuroscience

        section
          h3 Unsupervised clustering: Example #2

          p Segmenting images with spectral clustering

          a(href="http://scikit-learn.org/0.15/auto_examples/cluster/plot_lena_segmentation.html")
            img.method-example(src="img/unsupervised-clustering-spectral.png")

          aside.notes: ul
            li Hard clustering of pixels
            li Uncover different areas of the picture

      section
        section
          h3 Dimensionality reduction: Definition

          p <b>Dimensionality:</b> number of different feature types
          p <b>Reduction:</b> decreasing the feature number by selection or transformation

          aside.notes: ul
            li Often used as a preprocessing step
            li Can be used for exploration

        section
          h3 Dimensionality reduction: Example #1

          p Decomposing faces with principal component analysis

          a(href="http://scikit-learn.org/stable/auto_examples/decomposition/plot_faces_decomposition.html")
            img(src="img/dimensionality-reduction-original-faces.png", width="450")
            | &nbsp;
            img(src="img/dimensionality-reduction-pca-faces.png", width="450")

          aside.notes: ul
            li PCA: going strong since 1901
            li Denoise the data
            li Transform features to account for most of the variability
            li Right hand side: fuzzy, face-like images (eyes, nose, lips)

        section
          h3 Dimensionality reduction: Example #2

          p Discovering movie themes with matrix factorisation

          a(href="http://www2.research.att.com/~volinsky/papers/ieeespectrum.pdf")
            img.method-example(src="img/dimensionality-reduction-matrix-factorisation.png")

          aside.notes: ul
            li Matrix factorisation: similar to LDA and PCA
            li Features: ratings users gave to movies
            li Output: a vector with millions of ratings &ndash; handful of features that correspond to theme
            li Example: Movie is serious or light
            li More details in recsys talk

      section
        section
          h2 Beyond the map...

          ul
            li Preprocessing
            li Visualisation
            li Language processing: parse trees, part-of-speech tagging
            li Generation: written language, speech, movement
            li Active learning
            li And much more...

        section
          h2 Beyond the map...

          h1 Thinking and putting everything together

      section
        h2 The human behind the machine

        p Why are data scientists needed?

        ul
          li Ask questions
          li Reduce and rephrase problems
          li Come up with reasonable metrics
          li Choose the right tools
          li Handle data drift
          li Understand business needs
          li Make it work in production

        aside.notes: ul
          li More details later

      section
        h1 Questions?

    script(src="lib/js/head.min.js")
    script(src="js/reveal.js")
    script.
      Reveal.initialize({
        controls: true,
        controlsTutorial: false,
        progress: true,
        history: true,
        center: true,
        transition: 'slide',
        dependencies: [
          {
            src: 'lib/js/classList.js',
            condition: function() { return !document.body.classList; }
          },
          {
            src: 'plugin/markdown/marked.js',
            condition: function() { return !!document.querySelector( '[data-markdown]' ); }
          },
          {
            src: 'plugin/markdown/markdown.js',
            condition: function() { return !!document.querySelector( '[data-markdown]' ); }
          },
          {
            src: 'plugin/highlight/highlight.js',
            async: true,
            callback: function() { hljs.initHighlightingOnLoad(); }
          },
          {
            src: 'plugin/zoom-js/zoom.js',
            async: true
          },
          {
            src: 'plugin/notes/notes.js',
            async: true
          }
        ]
      });

<!DOCTYPE html><html lang="en"><head><title>Split testing calculator</title><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="Check the probability that your experiment succeeded. This calculator takes prior knowledge into account and makes a clear recommendation how to proceed."><link rel="stylesheet" href="style.css"></head><body><div class="container header"><h1 class="logo">Split testing calculator</h1><h2 class="tagline">Bayesian A/B experiments made easy</h2></div><div class="container"><div class="sidebar note-wrapper"><h3>Why another calculator?</h3><p class="note">There are many split testing calculators out there. Those based on frequentist statistics, <a
href="http://www.evanmiller.org/ab-testing/chi-squared.html" rel="nofollow" target="_blank">like Evan
Miller's</a>, assume a closed formula that requires <a
href="http://www.evanmiller.org/ab-testing/sample-size.html" rel="nofollow" target="_blank">setting the sample
size in advance</a>. Bayesian calculators, like <a href="http://developers.lyst.com/bayesian-calculator/"
rel="nofollow" target="_blank">Lyst's</a> (which formed the basis of this calculator), let users encode their
prior knowledge about the data, and do not require committing to a sample size in advance. This calculator
aims to make Bayesian A/B testing more accesible by reducing the use of jargon and making clearer
recommendations.</p><p class="note">Questions/comments? <a href="https://yanirseroussi.com/about" target="_blank">Drop me a line</a>
</p></div><div class="content"><h3 class="instructions-title">Instructions</h3><ol><li><span class="number">1</span>Specify the prior alpha and beta parameters.</li><li><span class="number">2</span>Plot the priors and revise parameters as necessary.</li><li><span class="number">3</span>Enter data on the number of successes and failures in the test and control groups.</li><li><span class="number">4</span>Plot to see posterior distributions.</li></ol></div></div><div class="container"><div class="sidebar"><form id="form"><h3 class="form-title">Your Data</h3><div class="form-group"><h4 class="form-group-title">Prior knowledge<span id="prior-params" class="dist-values"></span></h4><fieldset><label for="prior-mean">Success rate [%]</label><input id="prior-mean" value="50" type="number" min="0" max="100" step="any" placeholder="&gt; 0"></fieldset><fieldset><label for="prior-uncertainty">Uncertainty [%]</label><input id="prior-uncertainty" value="5" type="number" min="0" max="100" step="any" placeholder="&gt; 0"></fieldset></div><div class="form-group"><h4 class="form-group-title">Decision criterion</h4><fieldset><label for="minimum-effect">Minimum effect [%]</label><input id="minimum-effect" value="1" type="number" min="0" max="100" step="any" placeholder="&gt; 0"></fieldset></div><div class="form-group"><h4 class="form-group-title control">Control<span id="control-params" class="dist-values"></span></h4><fieldset><label for="control-trials">Trials</label><input id="control-trials" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset><fieldset><label for="control-successes">Successes</label><input id="control-successes" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset></div><div class="form-group"><h4 class="form-group-title test">Test<span id="test-params" class="dist-values"></span></h4><fieldset><label for="test-trials">Trials</label><input id="test-trials" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset><fieldset><label for="test-successes">Successes</label><input id="test-successes" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset></div><div class="form-buttons"><input type="submit" value="Calculate"><input type="reset" value="Reset"></div></form><p id="error-message" hidden></p><div class="result-summary"><p><i>Control success rate:&nbsp;</i><b id="control-success-rate"></b><br><i>Test success rate:&nbsp;</i><b id="test-success-rate"></b></p><p><i>Approximate probability that test performs better than control:</i><br><b><span id="test-success-probability"></span></b></p><p><i>Expected absolute change in success rate if test is chosen:</i><br><b><span id="difference-mean"></span></b></p><p><i>Recommendation:</i><br><b><span id="recommendation"></span></b></p><p class="chart-description">* Note: You can always decrease the risk of making the wrong decision by collecting more data. If your
sample size is small (less than a few hundred successes), or if it isn't representative of your population
(e.g., it was collected over a short period of time), it's probably worth continuing the experiment. If your
sample size is large and representative, but the difference between the control and test groups is
negligible, it's probably worth moving on to other experiments.</p><p class="chart-description">** Recommendation explanation: <span id="recommendation-explanation"></span>
</p></div></div><div class="content"><div class="chart"><h2 class="chart-title">Test and Control Probability Density Functions</h2><p class="chart-description">The success probability distributions in test and control groups.</p><div id="pdfplot"></div></div><div class="chart"><h2 class="chart-title">Histogram of Test - Control Probability</h2><p class="chart-description">Distribution of differences in success probability between test and control groups.</p><div id="histogram"></div></div><div class="chart"><h2 class="chart-title">Quantiles of the differences distribution.</h2><p class="chart-description">Posterior probability that the difference lies below the value x.</p><table id="quantile-table"></table></div></div></div><script type="text/javascript" src="bayes.min.js"></script></body></html>
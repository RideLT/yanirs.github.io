<!DOCTYPE html><html lang="en"><head><title>Split testing calculator</title><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><meta name="description" content="Check the probability that your experiment succeeded. This calculator takes prior knowledge into account and makes a clear recommendation how to proceed."><link rel="stylesheet" href="style.css"></head><body><div class="container header"><h1 class="logo">Split testing calculator</h1><h2 class="tagline">Bayesian A/B experiments made easy</h2></div><div class="container"><div class="sidebar note-wrapper"><h3>Why another calculator?</h3><p class="note">There are many split testing calculators out there. Those based on frequentist statistics, <a
href="http://www.evanmiller.org/ab-testing/chi-squared.html" rel="nofollow" target="_blank">like Evan
Miller's</a>, assume a closed formula that requires <a
href="http://www.evanmiller.org/ab-testing/sample-size.html" rel="nofollow" target="_blank">setting the sample
size in advance</a>. Bayesian calculators, like <a href="http://developers.lyst.com/bayesian-calculator/"
rel="nofollow" target="_blank">Lyst's</a> (which formed the basis of this calculator), let users encode their
prior knowledge about the data, and do not require committing to a sample size in advance. This calculator
aims to make Bayesian A/B testing more accesible by reducing the use of jargon and making clearer
recommendations.</p><p class="note">Questions/comments? <a href="https://yanirseroussi.com/about" target="_blank">Drop me a line</a>
</p></div><div class="content"><h3 class="instructions-title">Instructions</h3><ol><li><span class="number">1</span>Specify your prior knowledge. Set the success rate to what you think the
average success rate is, and quantify your uncertainty (from 0 to 100, exclusive). For example, if you're
running an experiment optimising the conversion rate of a landing page, and historical conversion rates are
around 30%, set the success rate to 30, and use a low uncertainty value (e.g., 5).</li><li><span class="number">2</span>Specify the minimum effect that you care about. For example, if you only care
about absolute changes in conversion rate that exceed 2.5%, set the minimum to 2.5.</li><li><span class="number">3</span>Enter data on the number of trials and success in the control and test groups,
respectively.</li><li><span class="number">4</span>Plot the distributions and choose whether to follow the recommendation. Note
that each time you press <i>calculate</i>, you will get slightly different results due to the random
simulation procedure. This is completely normal &ndash; it is very important to remember that few things
are completely certain when it comes to experimentation!</li><li><span class="number">5</span> Share your results by copying the link of this page &ndash; it automatically
changes as you fill the form.</li></ol><p class="description">Note: I tried to strike a balance between making this a useful tool for laypeople, and providing rich
information for the more statistically-inclined. Feel free to ignore greyed-out text like this if you don't
want to dig too deep!
</p></div></div><div class="container"><div class="sidebar"><form id="form"><h3 class="form-title">Your Data</h3><div class="form-group"><h4 class="form-group-title">Prior knowledge</h4><fieldset><label for="prior-mean">Success rate [%]</label><input id="prior-mean" value="50" type="number" min="0" max="100" step="any" placeholder="&gt; 0"></fieldset><fieldset><label for="prior-uncertainty">Uncertainty [%]</label><input id="prior-uncertainty" value="5" type="number" min="0" max="100" step="any" placeholder="&gt; 0"></fieldset><div id="prior-params" class="dist-values"></div></div><div class="form-group"><h4 class="form-group-title">Decision criterion</h4><fieldset><label for="minimum-effect">Minimum effect [%]</label><input id="minimum-effect" value="1" type="number" min="0" max="100" step="any" placeholder="&gt; 0"></fieldset></div><div class="form-group"><h4 class="form-group-title control">Control</h4><fieldset><label for="control-trials">Trials</label><input id="control-trials" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset><fieldset><label for="control-successes">Successes</label><input id="control-successes" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset><div id="control-params" class="dist-values"></div></div><div class="form-group"><h4 class="form-group-title test">Test</h4><fieldset><label for="test-trials">Trials</label><input id="test-trials" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset><fieldset><label for="test-successes">Successes</label><input id="test-successes" value="0" type="number" min="0" placeholder="&gt;= 0"></fieldset><div id="test-params" class="dist-values"></div></div><div class="form-buttons"><input type="submit" value="Calculate"><input type="reset" value="Reset"></div></form><p id="error-message" hidden></p><div class="result-summary"><p><i>Control success rate:&nbsp;</i><b id="control-success-rate"></b><br><i>Test success rate:&nbsp;</i><b id="test-success-rate"></b></p><p><i>Approximate probability that test performs better than control:</i><br><b><span id="test-success-probability"></span></b></p><p><i>Expected absolute change in success rate if test is chosen:</i><br><b><span id="difference-mean"></span></b></p><p><i>Recommendation:</i><br><b><span id="recommendation"></span></b></p><p class="description">* Note: You can always decrease the risk of making the wrong decision by collecting more data. If your
sample size is small (less than a few hundred successes), or if it isn't representative of your population
(e.g., it was collected over a short period of time), it's probably worth continuing the experiment. If your
sample size is large and representative, but the difference between the control and test groups is
negligible, it's probably worth moving on to other experiments.</p><p class="description">** Recommendation explanation: <span id="recommendation-explanation"></span>
</p></div></div><div class="content"><div class="chart"><h2 class="chart-title">Control and test probability density functions</h2><p class="description">The success rate distributions in control and test groups. The blue and red areas show the density
of the control and test distributions, respectively (the distributions completely overlap if you don't enter
any data). Success rates that fall within a high density interval are more likely than those that fall in
areas of low density.</p><div id="pdfplot"></div></div><div class="chart"><h2 class="chart-title">Difference between test and control</h2><p class="description">Distribution of differences in success probability between test and control groups. Obtained by simulating
draws from the test and control distributions, where each sample is a possible success probability for the
given group. Each control sample is paired with a test sample, and a difference sample is obtained by
subtracting control from test.</p><div id="histogram"></div></div><div class="chart"><h2 class="chart-title">Distribution intervals</h2><p class="description">The range of values contained in each central interval. For example, the first row shows the minimum and
maximum values of the control, test, and difference distributions, for the 99% interval (i.e., where 99%
of the values of each distribution fall &ndash; between the 0.5% and 99.5% percentiles). Note that the
difference bounds aren't necessarily the same as test minus the control bounds.</p><table id="quantile-table"></table></div></div></div><script type="text/javascript" src="bayes.min.js"></script></body></html>
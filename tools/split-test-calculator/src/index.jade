doctype html
html(lang="en")
  head
    title Split testing calculator
    meta(charset="utf-8")
    meta(name="viewport", content="width=device-width, initial-scale=1")
    link(rel="stylesheet", href="style.css")

  body
    .container.header
      h1.logo Split testing calculator
      h2.tagline Bayesian A/B experiments made easy

    .container
      .sidebar.note-wrapper
        h3 Why another calculator?
        p.note.
          There are many split testing calculators out there. Those based on frequentist statistics, <a
          href="http://www.evanmiller.org/ab-testing/chi-squared.html" rel="nofollow" target="_blank">like the one by
          Evan Miller</a>, assume a closed formula that requires <a
          href="http://www.evanmiller.org/ab-testing/sample-size.html" rel="nofollow" target="_blank">setting the sample
          size in advance</a>. Bayesian calculators, like <a href="http://developers.lyst.com/bayesian-calculator/"
          rel="nofollow" target="_blank">Lyst's calculator</a>, allow users to encode their prior knowledge about the
          data, and do not require committing to a sample size in advance. This calculator enhances Lyst's work, making
          it easier for users to specify prior knowledge and interpret the results.<br>
          Questions/comments? <a href="https://yanirseroussi.com/about" target="_blank">Drop me a line</a>

      .content
        h3.instructions-title Instructions
        ol
          li <span class="number">1</span>Specify the prior alpha and beta parameters.
          li <span class="number">2</span>Plot the priors and revise parameters as necessary.
          li <span class="number">3</span>Enter data on the number of successes and failures in the test and control groups.
          li <span class="number">4</span>Plot to see posterior distributions.

    .container
      .sidebar
        form#form
          h3.form-title Your Data
          .form-group
            h4.form-group-title Prior knowledge
              span#prior-params.dist-values
            fieldset
              label(for="prior-mean") Success rate
              input#prior-mean(value="0.5", type="number", min="0.001", max="0.999", step="0.001", placeholder="> 0")
            fieldset
              label(for="prior-uncertainty") Uncertainty
              input#prior-uncertainty(value="0.05", type="number", min="0.001", max="0.999", step="0.001",
                                      placeholder="> 0")

          .form-group
            h4.form-group-title.control Control
              span#control-params.dist-values
            fieldset
              label(for="control-trials") Trials
              input#control-trials(value="0", type="number", min="0", placeholder=">= 0")
            fieldset
              label(for="control-successes") Successes
              input#control-successes(value="0", type="number", min="0", placeholder=">= 0")

          .form-group
            h4.form-group-title.test Test
              span#test-params.dist-values
            fieldset
              label(for="test-trials") Trials
              input#test-trials(value="0", type="number", min="0", placeholder=">= 0")
            fieldset
              label(for="test-successes") Successes
              input#test-successes(value="0", type="number", min="0", placeholder=">= 0")

          .form-buttons
            input(type="submit", value="Calculate")
            input(type="reset", value="Reset")

        p#error-message(hidden)

        .result-summary
          p
            i Control success rate:&nbsp;
            b#control-success-rate
            br
            i Test success rate:&nbsp;
            b#test-success-rate
          p
            i Approximate probability that test performs better than control:
            br
            b: span#test-success-probability
          p
            i Expected change in success rate if test is chosen:
            br
            b: span#difference-mean
          p
            i Recommendation:
            br
            b: span#recommendation
          p.chart-description.
            * Note: You can always decrease your risk of making the wrong decision by collecting more data. If your
            sample size is small (less than a few hundred successes), or if it isn't representative of your population
            (e.g., it was collected over a short period of time), it's probably worth continuing the experiment. If your
            sample size is large and representative, but the difference between the control and test groups is small,
            it's probably worth moving on to other experiments.

      .content
        .chart
          h2.chart-title Test and Control Probability Density Functions
          p.chart-description The success probability distributions in test and control groups.
          #pdfplot

        .chart
          h2.chart-title Histogram of Test - Control Probability
          p.chart-description Distribution of differences in success probability between test and control groups.
          #histogram

        .chart
          h2.chart-title Quantiles of the differences distribution.
          p.chart-description Posterior probability that the difference lies below the value x.
          table#quantile-table

    script(type="text/javascript", src="bayes.min.js")

doctype html
html(lang="en")
  head
    title Split testing calculator
    meta(charset="utf-8")
    meta(name="viewport", content="width=device-width, initial-scale=1")
    meta(name="description",
         content="Check the probability that your experiment succeeded. " +
                 "This calculator takes prior knowledge into account and makes a clear recommendation how to proceed.")
    link(rel="stylesheet", href="style.css")

  body
    .container.header
      h1.logo Split testing calculator
      h2.tagline Bayesian A/B experiments made easy

    .container
      .sidebar.note-wrapper
        h3 Why another calculator?
        p.note.
          There are many split testing calculators out there. Those based on frequentist statistics, <a
          href="http://www.evanmiller.org/ab-testing/chi-squared.html" rel="nofollow" target="_blank">like Evan
          Miller's</a>, assume a closed formula that requires <a
          href="http://www.evanmiller.org/ab-testing/sample-size.html" rel="nofollow" target="_blank">setting the sample
          size in advance</a>. Bayesian calculators, like <a href="http://developers.lyst.com/bayesian-calculator/"
          rel="nofollow" target="_blank">Lyst's</a> (which formed the basis of this calculator), let users encode their
          prior knowledge about the data, and do not require committing to a sample size in advance. This calculator
          aims to make Bayesian A/B testing more accesible by reducing the use of jargon and making clearer
          recommendations.
        p.note.
          Questions/comments? <a href="https://yanirseroussi.com/about" target="_blank">Drop me a line</a>

      .content
        h3.instructions-title Instructions
        ol
          li.
            <span class="number">1</span>Specify your prior knowledge. Set the success rate to what you think the
            average success rate is, and quantify your uncertainty (from 0 to 100, exclusive). For example, if you're
            running an experiment optimising the conversion rate of a landing page, and historical conversion rates are
            around 30%, set the success rate to 30, and use a low uncertainty value (e.g., 5).
          li.
            <span class="number">2</span>Specify the minimum effect that you care about. For example, if you only care
            about absolute changes in conversion rate that exceed 2.5%, set the minimum to 2.5.
          li.
            <span class="number">3</span>Enter the number of trials and successes in the control and test groups.
          li.
            <span class="number">4</span>Plot the distributions and choose whether to follow the recommendation. Note
            that each time you press <i>calculate</i>, you will get slightly different results due to the random
            simulation procedure. This is completely normal &ndash; it is very important to remember that few things
            are completely certain when it comes to experimentation.
          li.
            <span class="number">5</span> Share your results by copying this page's link &ndash; it automatically
            changes to save your input when you press <i>calculate</i>.
        p.description.
          Note: I tried to strike a balance between making this a useful tool for laypeople and providing rich
          information for the more statistically-inclined. Feel free to ignore greyed-out text like this if you don't
          want to dig too deep.

    .container
      .sidebar
        form#form
          h3.form-title Your Data
          .form-group
            h4.form-group-title Prior knowledge
            fieldset
              label(for="prior-mean") Success rate [%]
              input#prior-mean(value="50", type="number", min="0", max="100", step="any", placeholder="> 0")
            fieldset
              label(for="prior-uncertainty") Uncertainty [%]
              input#prior-uncertainty(value="5", type="number", min="0", max="100", step="any", placeholder="> 0")
            #prior-params.dist-values

          .form-group
            h4.form-group-title Decision criterion
            fieldset
              label(for="minimum-effect") Minimum effect [%]
              input#minimum-effect(value="1", type="number", min="0", max="100", step="any", placeholder="> 0")

          .form-group
            h4.form-group-title.control Control
            fieldset
              label(for="control-trials") Trials
              input#control-trials(value="0", type="number", min="0", placeholder=">= 0")
            fieldset
              label(for="control-successes") Successes
              input#control-successes(value="0", type="number", min="0", placeholder=">= 0")
            #control-params.dist-values

          .form-group
            h4.form-group-title.test Test
            fieldset
              label(for="test-trials") Trials
              input#test-trials(value="0", type="number", min="0", placeholder=">= 0")
            fieldset
              label(for="test-successes") Successes
              input#test-successes(value="0", type="number", min="0", placeholder=">= 0")
            #test-params.dist-values

          .form-buttons
            input(type="submit", value="Calculate")
            input(type="reset", value="Reset")

        p#error-message(hidden)

        .result-summary
          p
            i Control success rate:&nbsp;
            b#control-success-rate
            br
            i Test success rate:&nbsp;
            b#test-success-rate
          p
            i Approximate probability that test performs better than control:
            br
            b: span#test-success-probability
          p
            i Expected absolute change in success rate if test is chosen:
            br
            b: span#difference-mean
          p
            i Recommendation:
            br
            b: span#recommendation
          p.description.
            * Note: You can always decrease the risk of making the wrong decision by collecting more data. If your
            sample size is small (less than a few hundred successes), or if it isn't representative of your population
            (e.g., it was collected over a short period of time), it's probably worth continuing the experiment. If your
            sample size is large and representative, but the difference between the control and test groups is
            negligible, it's probably worth moving on to other experiments.
          p.description.
            ** Recommendation explanation: <span id="recommendation-explanation"></span>

      .content
        .chart
          h2.chart-title Control and test probability density functions
          p.description.
            The success rate distributions for the control (blue) and test (red) groups.  The distributions completely
            overlap if no data is entered, or if the counts for each group are identical. Success rates that fall within
            high density intervals are more likely than those that fall in areas of low density.
          #pdfplot

        .chart
          h2.chart-title Difference between test and control
          p.description.
            Distribution of differences in success probability between test and control groups. Obtained by simulating
            draws from the test and control distributions, where each sample is a possible success probability for the
            given group. Each control sample is paired with a test sample, and a difference sample is obtained by
            subtracting the control value from the test value.
          #histogram

        .chart
          h2.chart-title Distribution intervals
          p.description.
            The range of values contained in each central interval. For example, the first row shows the minimum and
            maximum values of the control, test, and difference distributions, for the 99% interval (i.e., where 99%
            of the values of each distribution fall &ndash; between the 0.5% and 99.5% percentiles). Note that the
            bounds for the difference distribution aren't necessarily the same as test minus the control bounds.
          table#quantile-table

    script(type="text/javascript", src="bayes.min.js")
